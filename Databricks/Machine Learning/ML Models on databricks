Overview of Databricks:

Databricks: 
- An enterprise software company founded by the creators of Apache spark. The company has also created Delta Lake, MLFlow, Koalas, and all open
source projects that span data engineering, data science, and machine learning
- A cloud native platform for big data processing, machine learning, and analytics built using Data Lakehouse architecture

- Databricks provides unified set of tools for enterprise-grade solutions
- Tools for building, deploying, sharing and maintaining these solutions
- Is clould native - manages and deploys cloud infrastructure on your behalf
- Integrates with cloud storage and security in your cloud
- Available on AWS, Azure, GCP

Databricks Core tools:
1. Apache Spark for big data processing
2. Delta Lakes to allow ACID transactions, versioning on huge datasets (metadata on top of data lets you do ACID)
3. SQL engine to run queries and build dashboards
4. Popular ML tools for traditional and deep learning models

Databricks provides the resources and tools needed to build and maintain Spark-based applications and also includes features to simplify business
analytics and build ML pipelines


Databricks Data Analytics platform  (3 personas/env)
1. Databricks SQL: Platform for analysts to run SQL queries on data, create visualizations, share dashboards
2. Databricks Data Science and Engineering: Interactive workspace for collaboration between data engineers, data science, and ML engineers to generate 
   insights using spark
3. Databricks ML: Integrated end-to-end machine learning environment with managed services for ML workflow


Databricks ML Runtime:
- Automates the creation of cluster optimized for Machine Learning
- Includes popular ML libraries:
  -> scikit-learn
  -> XGBoost
  -> SparkML
  -> Tensorflow
  -> PyTorch
- For training huge amount of data, includes support for distributed training libraries such as Horovod
- Include tools to automate the model development process
- Performs hyperparameter tuning to find the best model


Automate Machine Learning:
- AutoML: Automatically creates, tunes and evaluates model
- Managed ML Flow: Manages end-to-end model lifecycle, including tracking experiment runs, deploying, registering
                   and sharing model
- Hyperopt: Uses the sparktrials class to simplify hyperparameter tuning by automating and distributing model tuning runs


End to End Machine Learning Environment:

  Data Preparation ---> Feature Store  --> Model Training  --->   Models ---->   Production
  (Data Sources)        (Feature Store)    (AutoML)                              (Batch/Streaming Inference)
  (Delta Tables)                           (Notebooks)                           (Online Serving endpoints)
                                           (Experiments)

  Data Preparation: Use Spark or native programming language libraries to connect to data sources
                    Delta tables offers transaction support, version control, revision history for huge datasets
  Feature Store: Feature table in feature store allows you to store processed features for model training and inference
  Model training: Model training can be performed using custom code or with AutoML
                  Track parameters and model using experiments with MLflow tracking
  Models: Explore, register and serve model using model registry
  Production: Deploy models to production and perform inference on batch as well as streaming data


MLFlow:
Open source platform for managing end-to-end machine learning lifecycle which includes model tracking, model registry
model serving and inference.

MLFlow Components:
1. Model tracking
2. Models
3. Projects
4. Model registry
5. Model serving

Model tracking:
- API and UI for logging parameters, code versions, metrics and output files
- Tracking lets you log and query experiments
- Supported technologies and languages include Python, REST, R API and Java API

MLflow tracking concepts:
- Experiment
- Runs

Experiments:
- Primary unit of organization and access control for runs
- Allows you to visualize, search for, and compare runs
- Two types of experiments:
  -> Workspace Experiment
     - Belongs to workspace and not associated with notebook
     - Runs in any notebook can use this experiment
  -> Notebook experiment
     - Associated with specific notebook
     - Automatically created if there is no active experiment for a run

Runs:
- Single execution of model code
- Contains the following info:
  -> Notebook
  -> Version
  -> Start and End time
  -> Metrics
  -> tags
  -> artifacts

Models and Model Serving:
- Manage and deploy models built using popular machine learning libraries
- Supports multiple model serving and inference platform
  -> Classic MLFlow model serving using REST endpoints
  -> Serverless real time inferencing allows scalable REST endpoints

Projects:
- Package ML Code in a reusable and reproducible form
- Allows sharing with other data scientists or transfers to production

Model Registry:
- Centralized model store where models can be registered and stored
- Manage lifecycle stage transitions from staging to production
- Allows versioning and annotation of models











































































